{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCV30xyVhFbE",
        "outputId": "875b1e89-2eb8-48b9-b5d3-be7f80155820"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqLRKhEF0TA7",
        "outputId": "b7ee69ea-f743-466f-aa03-9c59dba4832e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preporecessing"
      ],
      "metadata": {
        "id": "9pIkeiJyI5HL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XP_sfRV0VEu",
        "outputId": "6e333774-2bc8-4f49-a7d0-5569ccce4183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1832 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory(\"Training and Validation/\",\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgcImD-a0WWh",
        "outputId": "c1b45c27-e1b7-4cd9-f71c-56f5070e4ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 68 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('Testing/',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developing CNN Model"
      ],
      "metadata": {
        "id": "joHizqvQI9_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze59g_d20ZJ9"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4ZabBdR0kCb",
        "outputId": "c83b1559-ce00-4e89-c8f3-2a1d68f10fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "58/58 [==============================] - 7s 114ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.1130 - val_accuracy: 0.9559\n",
            "Epoch 2/25\n",
            "58/58 [==============================] - 6s 107ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.1251 - val_accuracy: 0.9559\n",
            "Epoch 3/25\n",
            "58/58 [==============================] - 6s 110ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.1683 - val_accuracy: 0.9265\n",
            "Epoch 4/25\n",
            "58/58 [==============================] - 7s 113ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.1858 - val_accuracy: 0.9265\n",
            "Epoch 5/25\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0279 - accuracy: 0.9891 - val_loss: 0.1003 - val_accuracy: 0.9706\n",
            "Epoch 6/25\n",
            "58/58 [==============================] - 7s 115ms/step - loss: 0.0281 - accuracy: 0.9929 - val_loss: 0.1395 - val_accuracy: 0.9559\n",
            "Epoch 7/25\n",
            "58/58 [==============================] - 7s 111ms/step - loss: 0.0271 - accuracy: 0.9874 - val_loss: 0.1844 - val_accuracy: 0.9412\n",
            "Epoch 8/25\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0379 - accuracy: 0.9847 - val_loss: 0.1402 - val_accuracy: 0.9412\n",
            "Epoch 9/25\n",
            "58/58 [==============================] - 7s 119ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.1122 - val_accuracy: 0.9412\n",
            "Epoch 10/25\n",
            "58/58 [==============================] - 7s 114ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.1654 - val_accuracy: 0.9559\n",
            "Epoch 11/25\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.1655 - val_accuracy: 0.9559\n",
            "Epoch 12/25\n",
            "58/58 [==============================] - 7s 118ms/step - loss: 0.0296 - accuracy: 0.9891 - val_loss: 0.1192 - val_accuracy: 0.9559\n",
            "Epoch 13/25\n",
            "58/58 [==============================] - 7s 113ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 0.1091 - val_accuracy: 0.9412\n",
            "Epoch 14/25\n",
            "58/58 [==============================] - 7s 128ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0758 - val_accuracy: 0.9706\n",
            "Epoch 15/25\n",
            "58/58 [==============================] - 8s 142ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1297 - val_accuracy: 0.9559\n",
            "Epoch 16/25\n",
            "58/58 [==============================] - 7s 126ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.1548 - val_accuracy: 0.9412\n",
            "Epoch 17/25\n",
            "58/58 [==============================] - 8s 144ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.1343 - val_accuracy: 0.9853\n",
            "Epoch 18/25\n",
            "58/58 [==============================] - 8s 137ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.1102 - val_accuracy: 0.9706\n",
            "Epoch 19/25\n",
            "58/58 [==============================] - 7s 129ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 0.3251 - val_accuracy: 0.9412\n",
            "Epoch 20/25\n",
            "58/58 [==============================] - 7s 122ms/step - loss: 0.0377 - accuracy: 0.9842 - val_loss: 0.1782 - val_accuracy: 0.9559\n",
            "Epoch 21/25\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 0.3444 - val_accuracy: 0.9412\n",
            "Epoch 22/25\n",
            "58/58 [==============================] - 7s 120ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.2316 - val_accuracy: 0.9559\n",
            "Epoch 23/25\n",
            "58/58 [==============================] - 7s 121ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 0.2052 - val_accuracy: 0.9559\n",
            "Epoch 24/25\n",
            "58/58 [==============================] - 7s 114ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.2005 - val_accuracy: 0.9559\n",
            "Epoch 25/25\n",
            "58/58 [==============================] - 7s 117ms/step - loss: 0.0180 - accuracy: 0.9924 - val_loss: 0.2536 - val_accuracy: 0.9412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x17bf0f1fa60>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Prediction"
      ],
      "metadata": {
        "id": "tPP_vLkGJFw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Risk_GlgCAlT",
        "outputId": "1f85d57e-d07d-43f8-988b-ca6e223a73ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fire': 0, 'nofire': 1}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH24phfVCAlV"
      },
      "source": [
        "<img src=\"SinglePrediction/abc175.jpg\" alt=\"title\" style=\"float: left; margin-right: 10px;\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ourY9OJj0nbH",
        "outputId": "e68c29e1-442f-4e65-b9fd-640f9bd6c5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "fire\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('SinglePrediction/abc175.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'fire'\n",
        "else:\n",
        "  prediction = 'nofire'\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yODoaEPDCAld"
      },
      "source": [
        "<img src=\"SinglePrediction/abc363.jpg\" alt=\"title\" style=\"float: left; margin-right: 10px;\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZwWYQrkCAle",
        "outputId": "b71c3ef1-2f94-433b-d2ba-30ec5e466655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "nofire\n"
          ]
        }
      ],
      "source": [
        "test_image = image.load_img('SinglePrediction/abc363.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'fire'\n",
        "else:\n",
        "  prediction = 'nofire'\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhafBdtfCAli"
      },
      "source": [
        "<img src=\"SinglePrediction/abc317.jpg\" alt=\"title\" style=\"float: left; margin-right: 10px;\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydoW0YPKCAlq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}